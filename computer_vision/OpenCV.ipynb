{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-5d37284fb7e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#Richard Wang\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "%matplotlib inline\n",
    "import ganymede\n",
    "ganymede.configure('uav.beaver.works')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "#Richard Wang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(p): pass\n",
    "check(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note\n",
    "\n",
    "`cv2.imshow()` will not work in a notebook, even though the OpenCV tutorials use it. Instead, use `plt.imshow` and family to visualize your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-b1076258c36f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlightningbolt\u001b[0m      \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'shapes/lightningbolt.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_GRAYSCALE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mblob\u001b[0m               \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'shapes/blob.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_GRAYSCALE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mstar\u001b[0m               \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'shapes/star.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_GRAYSCALE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msquishedstar\u001b[0m       \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'shapes/squishedstar.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_GRAYSCALE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msquishedturnedstar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'shapes/squishedturnedstar.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_GRAYSCALE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "lightningbolt      = cv2.imread('shapes/lightningbolt.png', cv2.IMREAD_GRAYSCALE)\n",
    "blob               = cv2.imread('shapes/blob.png', cv2.IMREAD_GRAYSCALE)\n",
    "star               = cv2.imread('shapes/star.png', cv2.IMREAD_GRAYSCALE)\n",
    "squishedstar       = cv2.imread('shapes/squishedstar.png', cv2.IMREAD_GRAYSCALE)\n",
    "squishedturnedstar = cv2.imread('shapes/squishedturnedstar.png', cv2.IMREAD_GRAYSCALE)\n",
    "letterj            = cv2.imread('shapes/letterj.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "images = [lightningbolt, blob, star, squishedstar, squishedturnedstar, letterj]\n",
    "\n",
    "fig,ax = plt.subplots(nrows=3, ncols=2)\n",
    "for a,i in zip(ax.flatten(), images):\n",
    "    a.imshow(i, cmap='gray', interpolation='none');\n",
    "fig.set_size_inches(7,14);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intensity_values = set(lightningbolt.flatten())\n",
    "print(len(intensity_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question:\n",
    "\n",
    "What would you expect the value to be, visually? What explains the actual value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Your Answer\n",
    "'''Expect to be 2 and actually it is 75. It happens because there are intensities that human eyes\n",
    "can not perceive besides black and white'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thresholding\n",
    "\n",
    "https://docs.opencv.org/3.4.1/d7/d4d/tutorial_py_thresholding.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, lightningbolt = cv2.threshold(lightningbolt,0,255,cv2.THRESH_BINARY)\n",
    "\n",
    "intensity_values = set(lightningbolt.flatten())\n",
    "print(len(intensity_values))\n",
    "\n",
    "plt.imshow(lightningbolt, cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question\n",
    "What happens when the above values are used for thresholding? What is a \"good\" value for thresholding the above images? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO\n",
    "## Your answer\n",
    "'''There are only two values now. A good value would be close to 255 in order to turn all the bright color\n",
    "into white while keeping most of the dark color black. This makes the image the most distinct.'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "**Steps**\n",
    "\n",
    "1. Read each tutorial\n",
    "    * Skim all parts of each tutorial to understand what each operation does\n",
    "    * Focus on the part you will need for the requested transformation\n",
    "2. Apply the transformation and visualize it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Blend lightningbolt and blob together\n",
    "https://docs.opencv.org/3.4.1/d0/d86/tutorial_py_image_arithmetics.html\n",
    "\n",
    "*Remember:* Don't use `imshow` from OpenCV, use `imshow` from `matplotlib`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Blend\n",
    "# TODO\n",
    "lightningbolt      = cv2.imread('shapes/lightningbolt.png', cv2.IMREAD_GRAYSCALE)\n",
    "blob               = cv2.imread('shapes/blob.png', cv2.IMREsubAD_GRAYSCALE)\n",
    "dst = cv.addWeighted(lightningbolt,0.7,blob,0.3,0)\n",
    "\n",
    "fig,ax = plt.subplots(nrows=3, ncols=2)\n",
    "print(len(ax.flatten()))\n",
    "for a,i in zip(ax.flatten(), images):\n",
    "    a.imshow(i, cmap='gray', interpolation='none');\n",
    "fig.set_size_inches(7,14);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Find a ROI which contains the point of the lightning bolt\n",
    "\n",
    "https://docs.opencv.org/3.4.1/d3/df2/tutorial_py_basic_ops.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. ROI\n",
    "# TODO\n",
    "lightningbolt      = cv2.imread('shapes/lightningbolt.png', cv2.IMREAD_GRAYSCALE)\n",
    "point = lightningbolt[150:175, 150:175]\n",
    "\n",
    "plt.subplot(121),plt.imshow(lightningbolt),plt.title('original')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(121),plt.imshow(point),plt.title('point')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Use an averaging kernel on the letter j\n",
    "\n",
    "https://docs.opencv.org/3.4.1/d4/d13/tutorial_py_filtering.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-66fae245d005>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 3.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# TODO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mletterj\u001b[0m            \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'shapes/letterj.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_GRAYSCALE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mblur\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblur\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mletterj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mletterj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mletterl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m121\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Original'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "# 3. \n",
    "# TODO\n",
    "letterj            = cv2.imread('shapes/letterj.png', cv2.IMREAD_GRAYSCALE)\n",
    "blur = cv2.blur(letterj,(letterj.shape[1],letterl.shape[0]))\n",
    "plt.subplot(121),plt.imshow(letterj),plt.title('Original')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122),plt.imshow(blur),plt.title('Blurred')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Morphology\n",
    "\n",
    "https://docs.opencv.org/3.4.1/d9/d61/tutorial_py_morphological_ops.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Perform erosion on j with a 3x3 kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4\n",
    "# TODO\n",
    "letterj            = cv2.imread('shapes/letterj.png', cv2.IMREAD_GRAYSCALE)\n",
    "kernel = np.ones((3,3),np.uint8)\n",
    "erosion = cv.erode(img,kernel,iterations = 1)\n",
    "\n",
    "plt.subplot(121),plt.imshow(letterj),plt.title('Original')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122),plt.imshow(erosion),plt.title('Blurred')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Perform erosion on j with a 5x5 kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5\n",
    "# TODO\n",
    "letterj            = cv2.imread('shapes/letterj.png', cv2.IMREAD_GRAYSCALE)\n",
    "kernel = np.ones((5,5),np.uint8)\n",
    "erosion = cv2.erode(img,kernel,iterations = 1)\n",
    "\n",
    "plt.subplot(121),plt.imshow(letterj),plt.title('Original')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122),plt.imshow(erosion),plt.title('Blurred')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Perform erosion on j with __two__ iterations, using a kernel size of your choice\n",
    "\n",
    "Hint: look at the OpenCV API documentation. It is possible to perform two iterations of erosion in one line of Python!\n",
    "\n",
    "https://docs.opencv.org/3.4.1/d4/d86/group__imgproc__filter.html#gaeb1e0c1033e3f6b891a25d0511362aeb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6\n",
    "# TODO\n",
    "letterj            = cv2.imread('shapes/letterj.png', cv2.IMREAD_GRAYSCALE)\n",
    "kernel = np.ones((10,10),np.uint8)\n",
    "erosion = cv2.erode(img,kernel,iterations = 2)\n",
    "\n",
    "plt.subplot(121),plt.imshow(letterj),plt.title('Original')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122),plt.imshow(erosion),plt.title('Blurred')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Perform dilation on j with a 3x3 kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7\n",
    "# TODO\n",
    "letterj            = cv2.imread('shapes/letterj.png', cv2.IMREAD_GRAYSCALE)\n",
    "kernel = np.ones((3,3),np.uint8)\n",
    "dilation = cv.dilate(img,kernel,iterations = 1)\n",
    "\n",
    "plt.subplot(121),plt.imshow(letterj),plt.title('Original')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122),plt.imshow(dilation),plt.title('Blurred')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Perform dilation on j with a 5x5 kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8\n",
    "# TODO\n",
    "letterj            = cv2.imread('shapes/letterj.png', cv2.IMREAD_GRAYSCALE)\n",
    "kernel = np.ones((5,5),np.uint8)\n",
    "dilation = cv.dilate(img,kernel,iterations = 1)\n",
    "\n",
    "plt.subplot(121),plt.imshow(letterj),plt.title('Original')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122),plt.imshow(dilation),plt.title('Blurred')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. What is the effect of kernel size on morphology operations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9\n",
    "# TODO\n",
    "'''Kernel size affect the impact of a single iteration. \n",
    "The bigger the size is, the more impact the kernel has on the image in 1 iteration.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. What is the difference betweeen repeated iterations of a morphology operation with a small kernel, versus a single iteration with a large kernel?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10\n",
    "# TODO\n",
    "'''Assuming we have square kernels, repetaed iteration of a small and a single iteration with a large kernel\n",
    "does not make a difference under the condition that the relative values iteration and size are kept\n",
    "in a fix number. However when we are using non-square kernels repeated iteration will rapidly \n",
    "shifts away from the starting point, so will large kernel but at a slower pace. Generally, small kernel but repeated iteration\n",
    "is faster than large kernel with a single iteration.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Rotate the lightningbolt and star by 90 degrees\n",
    "\n",
    "https://docs.opencv.org/3.4.1/da/d6e/tutorial_py_geometric_transformations.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11\n",
    "# TODO\n",
    "lightningbolt      = cv2.imread('shapes/lightningbolt.png', cv2.IMREAD_GRAYSCALE)\n",
    "star               = cv2.imread('shapes/star.png', cv2.IMREAD_GRAYSCALE)\n",
    "rows,cols = lightningbolt.shape\n",
    "M = cv2.getRotationMatrix2D((cols/2,rows/2),90,1)\n",
    "dst1 = cv2.warpAffine(lightningbolt,M,(cols,rows))\n",
    "\n",
    "rows,cols = star.shape\n",
    "N = cv2.getRotationMatrix2D((cols/2,rows/2),90,1)\n",
    "dst2 = cv2.warpAffine(star,N,(cols,rows))\n",
    "\n",
    "\n",
    "plt.subplot(121),plt.imshow(dst1),plt.title('Original')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122),plt.imshow(dst2),plt.title('Blurred')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. STRETCH GOAL: \n",
    "\n",
    "Visualize the result of Laplacian, Sobel X, and Sobel Y on all of the images. Also, produce a combined image of both Sobel X and Sobel Y for each image. Is Exercise 1 the best way to do this? Are there other options? \n",
    "\n",
    "You should have 4 outputs (Laplacian, SobelX, SobelY, and the combination) for each input image visualized at the end.\n",
    "\n",
    "https://docs.opencv.org/3.4.1/d5/d0f/tutorial_py_gradients.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When you are done:\n",
    "\n",
    "You should have one or more images for each exercise.\n",
    "\n",
    "1. Double-check that you filled in your name at the top of the notebook!\n",
    "2. Click `File` -> `Export Notebook As` -> `PDF`\n",
    "3. Email the PDF to `YOURTEAMNAME@beaver.works` "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
